{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'spellchecker'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-3cd3a0a24806>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mimutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobject_detection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnon_max_suppression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpkg_resources\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mresource_filename\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mspellchecker\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSpellChecker\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'spellchecker'"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "from pkg_resources import resource_filename\n",
    "\n",
    "import requests\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pytesseract\n",
    "from imutils.object_detection import non_max_suppression\n",
    "\n",
    "\n",
    "class PyTextractor:\n",
    "    layer_names = ('feature_fusion/Conv_7/Sigmoid', 'feature_fusion/concat_3',)\n",
    "\n",
    "    def __init__(self, east=None):\n",
    "        pkg_east_model = resource_filename(__name__, 'mldata/frozen_east_text_detection.pb')\n",
    "        self.east = east or pkg_east_model\n",
    "        self._load_assets()\n",
    "\n",
    "    def get_image_text(self,\n",
    "                       image,\n",
    "                       width=320,\n",
    "                       height=320,\n",
    "                       display=False,\n",
    "                       numbers=False,\n",
    "                       confidence=0.5,\n",
    "                       percentage=2.0,\n",
    "                       min_boxes=1,\n",
    "                       max_iterations=20,\n",
    "                       **kwargs):\n",
    "        loaded_image = self._load_image(image)\n",
    "        image, width, height, ratio_width, ratio_height = self._resize_image(\n",
    "            loaded_image, width, height\n",
    "        )\n",
    "        scores, geometry = self._compute_scores_geometry(image, width, height)\n",
    "        (num_rows, num_cols) = scores.shape[2:4]\n",
    "\n",
    "        start = time.time()\n",
    "        boxes = self._get_boxes(num_rows, num_cols, confidence, geometry, scores, min_boxes, max_iterations)\n",
    "        end = time.time()\n",
    "        print('Found {boxes} ROIs {seconds:.6f} seconds'.format(boxes=len(boxes), seconds=(end - start)))\n",
    "\n",
    "        return self._extract_text(\n",
    "            loaded_image, boxes, percentage, display, numbers, ratio_width, ratio_height\n",
    "        )\n",
    "\n",
    "    def _load_image(self, image):\n",
    "        return cv2.imread(image)\n",
    "\n",
    "    def _resize_image(self, image, width, height):\n",
    "        (H, W) = image.shape[:2]\n",
    "\n",
    "        (newW, newH) = (width, height)\n",
    "        ratio_width = W / float(newW)\n",
    "        ratio_height = H / float(newH)\n",
    "\n",
    "\n",
    "        # resize the image and grab the new image dimensions\n",
    "        resized_image = cv2.resize(image, (newW, newH))\n",
    "        (H, W) = resized_image.shape[:2]\n",
    "        return (resized_image, height, width, ratio_width, ratio_height)\n",
    "\n",
    "    def _compute_scores_geometry(self, image, width, height):\n",
    "        # construct a blob from the image and then perform a forward pass of\n",
    "        # the model to obtain the two output layer sets\n",
    "        blob = cv2.dnn.blobFromImage(\n",
    "            image, 1.0, (width, height), (123.68, 116.78, 103.94), swapRB=True, crop=False\n",
    "        )\n",
    "        start = time.time()\n",
    "        self.east_net.setInput(blob)\n",
    "        (scores, geometry) = self.east_net.forward(self.layer_names)\n",
    "        end = time.time()\n",
    "\n",
    "        # show timing information on text prediction\n",
    "        print('[INFO] text detection took {:.6f} seconds'.format(end - start))\n",
    "        return (scores, geometry)\n",
    "\n",
    "    def _load_assets(self):\n",
    "        self._get_east()\n",
    "        start = time.time()\n",
    "        self.east_net = cv2.dnn.readNet(self.east)\n",
    "        end = time.time()\n",
    "        print('[INFO] Loaded EAST text detector {:.6f} seconds ...'.format(end - start))\n",
    "\n",
    "    def _get_east(self):\n",
    "        if os.path.exists(self.east):\n",
    "            return\n",
    "\n",
    "        pkg_path = os.path.dirname(__file__)\n",
    "        data_file = os.path.join(pkg_path, self.east)\n",
    "        os.makedirs(os.path.dirname(data_file))\n",
    "        print('Downloading east data file  to {}'.format(data_file))\n",
    "        with open(data_file, 'wb') as fp:\n",
    "            with requests.get('https://tinyurl.com/yxdd7kb5', stream=True) as response:\n",
    "                for chunk in response.iter_content(chunk_size=2048):\n",
    "                    fp.write(chunk)\n",
    "\n",
    "    def _get_boxes(self, num_rows, num_cols, confidence, geometry, scores, min_boxes, max_iterations):\n",
    "        iterations = 0\n",
    "        boxes = []\n",
    "        rects = []\n",
    "        confidences = []\n",
    "        while(iterations < max_iterations):\n",
    "            for y in range(0, num_rows):\n",
    "                # extract the scores (probabilities), followed by the geometrical\n",
    "                # data used to derive potential bounding box coordinates that\n",
    "                # surround text\n",
    "                scores_data = scores[0, 0, y]\n",
    "                x_data_0 = geometry[0, 0, y]\n",
    "                x_data_1 = geometry[0, 1, y]\n",
    "                x_data_2 = geometry[0, 2, y]\n",
    "                x_data_3 = geometry[0, 3, y]\n",
    "                angles_data = geometry[0, 4, y]\n",
    "\n",
    "                # loop over the number of columns\n",
    "                for x in range(0, num_cols):\n",
    "                    # if our score does not have sufficient probability, ignore it\n",
    "                    if scores_data[x] < confidence:\n",
    "                        continue\n",
    "\n",
    "                    # compute the offset_ factor as our resulting feature maps will\n",
    "                    # be 4x smaller than the input image\n",
    "                    (offset_X, offset_Y) = (x * 4.0, y * 4.0)\n",
    "\n",
    "                    # extract the rotation angle for the prediction and then\n",
    "                    # compute the sin and cosine\n",
    "                    angle = angles_data[x]\n",
    "                    cos = np.cos(angle)\n",
    "                    sin = np.sin(angle)\n",
    "\n",
    "                    # use the geometry volume to derive the width and height of\n",
    "                    # the bounding box\n",
    "                    h = x_data_0[x] + x_data_2[x]\n",
    "                    w = x_data_1[x] + x_data_3[x]\n",
    "\n",
    "                    # compute both the start_ing and end_ing (x, y)-coordinates for\n",
    "                    # the text prediction bounding box\n",
    "                    end_X = int(offset_X + (cos * x_data_1[x]) + (sin * x_data_2[x]))\n",
    "                    end_Y = int(offset_Y - (sin * x_data_1[x]) + (cos * x_data_2[x]))\n",
    "                    start_X = int(end_X - w)\n",
    "                    start_Y = int(end_Y - h)\n",
    "\n",
    "                    # add the bounding box coordinates and probability score to\n",
    "                    # our respective lists\n",
    "                    rects.append((start_X, start_Y, end_X, end_Y))\n",
    "                    confidences.append(scores_data[x])\n",
    "\n",
    "            # apply non-maxima suppression to suppress weak, overlapping bounding\n",
    "            # boxes\n",
    "            boxes = non_max_suppression(np.array(rects), probs=confidences)\n",
    "            if len(boxes) >= min_boxes:\n",
    "                return boxes\n",
    "            else:\n",
    "                confidence /= 2\n",
    "                print('Couldn\\'t find at least {min_boxes} boxe(s), halving confidence to {confidence}'.\n",
    "                      format(min_boxes=min_boxes, confidence=confidence))\n",
    "\n",
    "    def _extract_text(self, image, boxes, percent, display, numbers, ratio_width, ratio_height):\n",
    "        extracted_text = []\n",
    "        for (start_X, start_Y, end_X, end_Y) in boxes:\n",
    "            # scale the bounding box coordinates based on the respective\n",
    "            # ratios\n",
    "            percent = (percent / 100 + 1) if percent >= 0 else ((100 - percent) / 100)\n",
    "            start_X = int(start_X * ratio_width * percent)\n",
    "            start_Y = int(start_Y * ratio_height * percent)\n",
    "            end_X = int(end_X * ratio_width * percent)\n",
    "            end_Y = int(end_Y * ratio_height * percent)\n",
    "\n",
    "            # draw the bounding box on the image\n",
    "            if display:\n",
    "                cv2.rectangle(image, (start_X, start_Y), (end_X, end_Y), (0, 255, 0), 2)\n",
    "\n",
    "            ROIImage = image.copy()[start_Y:end_Y, start_X:end_X]\n",
    "            config = '--psm 6' if numbers else ''\n",
    "            extracted_text.append(pytesseract.image_to_string(\n",
    "                ROIImage, config=config)\n",
    "            )\n",
    "            if display:\n",
    "                cv2.imshow('SubImage', ROIImage)\n",
    "\n",
    "        # show the output image\n",
    "        if display:\n",
    "            cv2.imshow('Text Detection', image)\n",
    "            cv2.waitKey(0)\n",
    "\n",
    "        return extracted_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loaded EAST text detector 1.164478 seconds ...\n",
      "[INFO] text detection took 0.519857 seconds\n",
      "Found 27 ROIs 0.039847 seconds\n",
      "['M8691C', 'COVT.', 'Wate oF', '02/11/', '', '', '', '', '', '', '', 'THUKKARA', 'exit!', '', '', 'lumber Card', '', 'BIrtn', 'Account', '', '\"HUKKARAM', 'Permanent', 'MUTHUKRISHNAT', 'MENT', 'rather |', '', '']\n"
     ]
    }
   ],
   "source": [
    "extractor = PyTextractor()\n",
    "print(extractor.get_image_text(\"/Users/muthukrishnan/Downloads/scan2.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
